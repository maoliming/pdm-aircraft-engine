{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory:  /Users/syahrulhamdani/Desktop/thesis/predictive-maintenance-of-aircraft-engine\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# change working directory\n",
    "os.chdir('/Users/syahrulhamdani/Desktop/thesis/predictive-maintenance-of-aircraft-engine/')\n",
    "print('Working directory: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  \u001b[1m\u001b[36mdata\u001b[m\u001b[m       \u001b[1m\u001b[36mnotebooks\u001b[m\u001b[m  \u001b[1m\u001b[36mreferences\u001b[m\u001b[m \u001b[1m\u001b[36mreports\u001b[m\u001b[m    \u001b[1m\u001b[36msrc\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EngineID  Cycle  OpSetting1  OpSetting2  OpSetting3      T2     T24  \\\n",
      "0         1      1     -0.0007     -0.0004       100.0  518.67  641.82   \n",
      "1         1      2      0.0019     -0.0003       100.0  518.67  642.15   \n",
      "2         1      3     -0.0043      0.0003       100.0  518.67  642.35   \n",
      "3         1      4      0.0007      0.0000       100.0  518.67  642.35   \n",
      "4         1      5     -0.0019     -0.0002       100.0  518.67  642.37   \n",
      "\n",
      "       T30      T50     P2   ...        phi      NRf      NRc     BPR  farB  \\\n",
      "0  1589.70  1400.60  14.62   ...     521.66  2388.02  8138.62  8.4195  0.03   \n",
      "1  1591.82  1403.14  14.62   ...     522.28  2388.07  8131.49  8.4318  0.03   \n",
      "2  1587.99  1404.20  14.62   ...     522.42  2388.03  8133.23  8.4178  0.03   \n",
      "3  1582.79  1401.87  14.62   ...     522.86  2388.08  8133.83  8.3682  0.03   \n",
      "4  1582.85  1406.22  14.62   ...     522.19  2388.04  8133.80  8.4294  0.03   \n",
      "\n",
      "   htBleed  Nf_dmd  PCNfR_dmd    W31      W32  \n",
      "0      392    2388      100.0  39.06  23.4190  \n",
      "1      392    2388      100.0  39.00  23.4236  \n",
      "2      390    2388      100.0  38.95  23.3442  \n",
      "3      392    2388      100.0  38.88  23.3739  \n",
      "4      393    2388      100.0  38.90  23.4044  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "(20631, 26)\n"
     ]
    }
   ],
   "source": [
    "with open('references/col_to_feat.json', ) as f:\n",
    "    feature_names = json.load(f)\n",
    "feature_names = list(feature_names.values())\n",
    "dataset = pd.read_csv('data/raw/train_FD001.txt', header=None, names=feature_names, sep='\\s+')\n",
    "pprint(dataset.head(5), compact=True, width=50)\n",
    "pprint(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EngineID,Cycle,OpSetting1,OpSetting2,OpSetting3,T2,T24,T30,T50,P2,P15,P30,Nf,Nc,epr,Ps30,phi,NRf,NRc,BPR,farB,htBleed,Nf_dmd,PCNfR_dmd,W31,W32'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data class that will load particular dataset with input `filename.format`. Here, the steps are:\n",
    "\n",
    "1. Create a dict that maps key value to the existing dataset in the directory\n",
    "2. Initialization must pass `filename` and `directory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUL_FD001.txt   RUL_FD004.txt   test_FD003.txt  train_FD002.txt\r\n",
      "RUL_FD002.txt   test_FD001.txt  test_FD004.txt  train_FD003.txt\r\n",
      "RUL_FD003.txt   test_FD002.txt  train_FD001.txt train_FD004.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dict mapping the key to dataset filename:\n",
    "\n",
    "```python\n",
    "key_to_file = dict()\n",
    "for directory, _, files in os.walk('data/raw/'):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            key_to_file[file.split('.')[0]] = file\n",
    "print(key_to_file)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dataset(path='data/raw'):\n",
    "    \"\"\"return list of dataset exist in the `path`.\"\"\"\n",
    "    key_to_file = dict()\n",
    "    for directory, _, files in os.walk('data/raw/'):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                key_to_file[file.split('.')[0]] = file\n",
    "    \n",
    "    return key_to_file\n",
    "\n",
    "class LoadData:\n",
    "    key_to_file = dict()\n",
    "    for directory, _, files in os.walk('data/raw/'):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                key_to_file[file.split('.')[0]] = file\n",
    "    \n",
    "    def __init__(self, dict_to_file, folder='data/raw', names=None, sep='\\s+'):\n",
    "        \"\"\"Load the dataset with name `filename` from `path`.\n",
    "        \n",
    "        parameters\n",
    "        ----------\n",
    "        filename (str): the name of dataset exist in path\n",
    "        folder (str): directory where the data exist\n",
    "        \n",
    "        attributes\n",
    "        ----------\n",
    "        features: data features\n",
    "        target: data labels\n",
    "        \"\"\"\n",
    "        # load the data\n",
    "        file = os.path.join(folder, dict_to_file)\n",
    "        dataset = pd.read_csv(file, sep=sep, names=names)\n",
    "        self.features = dataset.values\n",
    "        self.target = self.__get_rul(dataset, names)\n",
    "    \n",
    "    def __get_rul(self, data, names):\n",
    "        \"\"\"return the remaining useful life for each cycle for each EngineID.\"\"\"\n",
    "        num_engine = pd.unique(data.iloc[:, 0]).shape[0]\n",
    "        num_cycle = [data.loc[data[names[0]]==i, names[0]].shape[0] for i in range(1, num_engine+1)]\n",
    "        rul = np.array([])\n",
    "        for engine in range(num_engine):\n",
    "            diff = num_cycle[engine] - data.loc[data[names[0]]==engine+1, names[1]].values\n",
    "            rul = np.append(rul, diff)\n",
    "        \n",
    "        return rul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_FD001': 'train_FD001.txt',\n",
       " 'train_FD003': 'train_FD003.txt',\n",
       " 'RUL_FD004': 'RUL_FD004.txt',\n",
       " 'train_FD002': 'train_FD002.txt',\n",
       " 'RUL_FD001': 'RUL_FD001.txt',\n",
       " 'RUL_FD003': 'RUL_FD003.txt',\n",
       " 'RUL_FD002': 'RUL_FD002.txt',\n",
       " 'train_FD004': 'train_FD004.txt',\n",
       " 'test_FD003': 'test_FD003.txt',\n",
       " 'test_FD002': 'test_FD002.txt',\n",
       " 'test_FD001': 'test_FD001.txt',\n",
       " 'test_FD004': 'test_FD004.txt'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_mapping = list_dataset()\n",
    "feature_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[[ 1.00000e+00  1.00000e+00 -7.00000e-04 -4.00000e-04  1.00000e+02\n",
      "   5.18670e+02  6.41820e+02  1.58970e+03  1.40060e+03  1.46200e+01\n",
      "   2.16100e+01  5.54360e+02  2.38806e+03  9.04619e+03  1.30000e+00\n",
      "   4.74700e+01  5.21660e+02  2.38802e+03  8.13862e+03  8.41950e+00\n",
      "   3.00000e-02  3.92000e+02  2.38800e+03  1.00000e+02  3.90600e+01\n",
      "   2.34190e+01]\n",
      " [ 1.00000e+00  2.00000e+00  1.90000e-03 -3.00000e-04  1.00000e+02\n",
      "   5.18670e+02  6.42150e+02  1.59182e+03  1.40314e+03  1.46200e+01\n",
      "   2.16100e+01  5.53750e+02  2.38804e+03  9.04407e+03  1.30000e+00\n",
      "   4.74900e+01  5.22280e+02  2.38807e+03  8.13149e+03  8.43180e+00\n",
      "   3.00000e-02  3.92000e+02  2.38800e+03  1.00000e+02  3.90000e+01\n",
      "   2.34236e+01]\n",
      " [ 1.00000e+00  3.00000e+00 -4.30000e-03  3.00000e-04  1.00000e+02\n",
      "   5.18670e+02  6.42350e+02  1.58799e+03  1.40420e+03  1.46200e+01\n",
      "   2.16100e+01  5.54260e+02  2.38808e+03  9.05294e+03  1.30000e+00\n",
      "   4.72700e+01  5.22420e+02  2.38803e+03  8.13323e+03  8.41780e+00\n",
      "   3.00000e-02  3.90000e+02  2.38800e+03  1.00000e+02  3.89500e+01\n",
      "   2.33442e+01]\n",
      " [ 1.00000e+00  4.00000e+00  7.00000e-04  0.00000e+00  1.00000e+02\n",
      "   5.18670e+02  6.42350e+02  1.58279e+03  1.40187e+03  1.46200e+01\n",
      "   2.16100e+01  5.54450e+02  2.38811e+03  9.04948e+03  1.30000e+00\n",
      "   4.71300e+01  5.22860e+02  2.38808e+03  8.13383e+03  8.36820e+00\n",
      "   3.00000e-02  3.92000e+02  2.38800e+03  1.00000e+02  3.88800e+01\n",
      "   2.33739e+01]\n",
      " [ 1.00000e+00  5.00000e+00 -1.90000e-03 -2.00000e-04  1.00000e+02\n",
      "   5.18670e+02  6.42370e+02  1.58285e+03  1.40622e+03  1.46200e+01\n",
      "   2.16100e+01  5.54000e+02  2.38806e+03  9.05515e+03  1.30000e+00\n",
      "   4.72800e+01  5.22190e+02  2.38804e+03  8.13380e+03  8.42940e+00\n",
      "   3.00000e-02  3.93000e+02  2.38800e+03  1.00000e+02  3.89000e+01\n",
      "   2.34044e+01]]\n",
      "[191. 190. 189. 188. 187.]\n"
     ]
    }
   ],
   "source": [
    "data = LoadData(feature_mapping['train_FD001'], names=feature_names)\n",
    "print(type(data.features), type(data.target))\n",
    "print(data.features[:5])\n",
    "print(data.target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 27)\n"
     ]
    }
   ],
   "source": [
    "processed_data = np.concatenate((data.features, data.target.reshape(data.target.shape[0], -1)), axis=1)\n",
    "print(processed_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save processed data into `data/processed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_title = np.append(feature_names, 'RUL')\n",
    "np.savetxt('data/processed/processed.csv', processed_data, delimiter=',', header=','.join(feature_title),\n",
    "           comments='', fmt='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
